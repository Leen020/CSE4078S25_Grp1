{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Leen020/CSE4078S25_Grp1/blob/main/delivery3/Gemma3_(1B)-GRPO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vh7F68e12nmv"
      },
      "source": [
        "To run this, press \"*Runtime*\" and press \"*Run all*\" on a **free** Tesla T4 Google Colab instance!\n",
        "<div class=\"align-center\">\n",
        "<a href=\"https://unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "<a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord button.png\" width=\"145\"></a>\n",
        "<a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a></a> Join Discord if you need help + ⭐ <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ⭐\n",
        "</div>\n",
        "\n",
        "To install Unsloth on your own computer, follow the installation instructions on our Github page [here](https://docs.unsloth.ai/get-started/installing-+-updating).\n",
        "\n",
        "You will learn how to do [data prep](#Data), how to [train](#Train), how to [run the model](#Inference), & [how to save it](#Save)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPdoAcga2nmy"
      },
      "source": [
        "### News"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95KfOlHo2nmy"
      },
      "source": [
        "Read our **[Qwen3 Guide](https://docs.unsloth.ai/basics/qwen3-how-to-run-and-fine-tune)** and check out our new **[Dynamic 2.0](https://docs.unsloth.ai/basics/unsloth-dynamic-2.0-ggufs)** quants which outperforms other quantization methods!\n",
        "\n",
        "Visit our docs for all our [model uploads](https://docs.unsloth.ai/get-started/all-our-models) and [notebooks](https://docs.unsloth.ai/get-started/unsloth-notebooks).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpVGLULt2nmz"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "H9K4PMDw2nm0"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import os\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth vllm\n",
        "else:\n",
        "    # [NOTE] Do the below ONLY in Colab! Use [[pip install unsloth vllm]]\n",
        "    !pip install --no-deps unsloth vllm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IgynUyZx2nm1"
      },
      "outputs": [],
      "source": [
        "#@title Colab Extra Install { display-mode: \"form\" }\n",
        "%%capture\n",
        "import os\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth vllm\n",
        "else:\n",
        "    !pip install --no-deps unsloth vllm\n",
        "    # [NOTE] Do the below ONLY in Colab! Use [[pip install unsloth vllm]]\n",
        "    # Skip restarting message in Colab\n",
        "    import sys, re, requests; modules = list(sys.modules.keys())\n",
        "    for x in modules: sys.modules.pop(x) if \"PIL\" in x or \"google\" in x else None\n",
        "    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft \"trl==0.15.2\" triton cut_cross_entropy unsloth_zoo\n",
        "    !pip install sentencepiece protobuf \"datasets>=3.4.1\" huggingface_hub hf_transfer\n",
        "\n",
        "    # vLLM requirements - vLLM breaks Colab due to reinstalling numpy\n",
        "    f = requests.get(\"https://raw.githubusercontent.com/vllm-project/vllm/refs/heads/main/requirements/common.txt\").content\n",
        "    with open(\"vllm_requirements.txt\", \"wb\") as file:\n",
        "        file.write(re.sub(rb\"(transformers|numpy|xformers)[^\\n]{1,}\\n\", b\"\", f))\n",
        "    !pip install -r vllm_requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gd2cpn1kaXRA"
      },
      "source": [
        "### Unsloth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rezoBIE1aXRA"
      },
      "source": [
        "Load up `Gemma 3 1B Instruct`, and set parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "DkIvEkIIkEyB",
        "outputId": "2f9b549d-52ff-4c57-fbd9-5901b7c8db7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-82f319bae61b>:1: UserWarning: WARNING: Unsloth should be imported before trl, transformers, peft to ensure all optimizations are applied. Your code may run slower or encounter memory issues without these optimizations.\n",
            "\n",
            "Please restructure your imports with 'import unsloth' at the top of your file.\n",
            "  from unsloth import FastModel\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "Unsloth currently only works on NVIDIA GPUs and Intel GPUs.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-82f319bae61b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0munsloth\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFastModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmax_seq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m fourbit_models = [\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unsloth currently only works on NVIDIA GPUs and Intel GPUs.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m \u001b[0mDEVICE_TYPE\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_device_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;31m# Reduce VRAM usage by reducing fragmentation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/__init__.py\u001b[0m in \u001b[0;36mget_device_type\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"xpu\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"xpu\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unsloth currently only works on NVIDIA GPUs and Intel GPUs.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0mDEVICE_TYPE\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_device_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: Unsloth currently only works on NVIDIA GPUs and Intel GPUs."
          ]
        }
      ],
      "source": [
        "from unsloth import FastModel\n",
        "import torch\n",
        "max_seq_length = 1024\n",
        "\n",
        "fourbit_models = [\n",
        "    # 4bit dynamic quants for superior accuracy and low memory use\n",
        "    \"unsloth/gemma-3-1b-it-unsloth-bnb-4bit\",\n",
        "    \"unsloth/gemma-3-4b-it-unsloth-bnb-4bit\",\n",
        "    \"unsloth/gemma-3-12b-it-unsloth-bnb-4bit\",\n",
        "    \"unsloth/gemma-3-27b-it-unsloth-bnb-4bit\",\n",
        "\n",
        "    # Other popular models!\n",
        "    \"unsloth/Llama-3.1-8B\",\n",
        "    \"unsloth/Llama-3.2-3B\",\n",
        "    \"unsloth/Llama-3.3-70B\",\n",
        "    \"unsloth/mistral-7b-instruct-v0.3\",\n",
        "    \"unsloth/Phi-4\",\n",
        "] # More models at https://huggingface.co/unsloth\n",
        "\n",
        "model, tokenizer = FastModel.from_pretrained(\n",
        "    model_name = \"unsloth/gemma-3-1b-it\",\n",
        "    max_seq_length = max_seq_length, # Choose any for long context!\n",
        "    load_in_4bit = False,  # 4 bit quantization to reduce memory\n",
        "    load_in_8bit = False, # [NEW!] A bit more accurate, uses 2x memory\n",
        "    full_finetuning = False, # [NEW!] We have full finetuning now!\n",
        "    # token = \"hf_...\", # use one if using gated models\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nHQVsQJ2roh"
      },
      "source": [
        "We now add LoRA adapters so we only need to update a small amount of parameters!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNuwc5sJ2pYK"
      },
      "outputs": [],
      "source": [
        "model = FastModel.get_peft_model(\n",
        "    model,\n",
        "    finetune_vision_layers     = False, # Turn off for just text!\n",
        "    finetune_language_layers   = True,  # Should leave on!\n",
        "    finetune_attention_modules = True,  # Attention good for GRPO\n",
        "    finetune_mlp_modules       = True,  # SHould leave on always!\n",
        "\n",
        "    r = 8,           # Larger = higher accuracy, but might overfit\n",
        "    lora_alpha = 8,  # Recommended alpha == r at least\n",
        "    lora_dropout = 0,\n",
        "    bias = \"none\",\n",
        "    random_state = 3407,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KGgPgk_5S8r"
      },
      "source": [
        "### Data Prep and Fetching from Github"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEibULDtlOMU"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "from datasets import Dataset\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/Leen020/CSE4078S25_Grp1/main/delivery3/CSE4078S25_Grp1_train_AlpacaStyle.json\"\n",
        "response = requests.get(url)\n",
        "\n",
        "# Check if the request was successful (status code 200)\n",
        "if response.status_code == 200:\n",
        "    try:\n",
        "        data = json.loads(response.text)\n",
        "\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(\"JSON Decode Error:\", e)\n",
        "        # Belki UTF-8 BOM veya görünmeyen karakterler vardır, onları temizleyelim\n",
        "        text_clean = response.text.encode('utf-8').decode('utf-8-sig')\n",
        "        try:\n",
        "            data = json.loads(text_clean)\n",
        "        except json.JSONDecodeError as e:\n",
        "             print(\"JSON Decode Error after cleaning:\", e)\n",
        "             print(\"Could not parse JSON even after cleaning.\")\n",
        "             data = None # Assign None or handle the error as appropriate\n",
        "else:\n",
        "    print(f\"Error: Received status code {response.status_code}\")\n",
        "    print(f\"Response content: {response.text}\")\n",
        "    data = None # Assign None or handle the error as appropriate\n",
        "\n",
        "if data is not None:\n",
        "    dataset = Dataset.from_list(data)\n",
        "    print(f\"Toplam örnek sayısı: {len(dataset)}\")\n",
        "    print(dataset[0])\n",
        "else:\n",
        "    print(\"Could not load data into a dataset.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "!pip install transformers datasets bitsandbytes unsloth huggingface_hub"
      ],
      "metadata": {
        "id": "TO8go1xTGjDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRfa3z_atGgT"
      },
      "source": [
        "Let's look at the first row:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "rIRsNJ_YitXl",
        "outputId": "f33827c3-7a50-4d13-8058-8395cb3c68ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Aşağıdaki cümledeki kelimelere doğru NER etiketlerini ekleyin.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "dataset[0][\"instruction\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "B3yJTiFgtKYq",
        "outputId": "7fe6448c-70e2-4413-b7b1-bca062b7fe26"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Albüm satış rakamlarıyla dikkat çekmiştir .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "dataset[0][\"input\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0][\"output\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Odr1A8Y7GY-x",
        "outputId": "72580731-dd0f-4a62-9eb4-e965ad38b7cd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Albüm: O, satış: O, rakamlarıyla: O, dikkat: O, çekmiştir: O, .: O'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFRYlk9ntYTm"
      },
      "source": [
        "Let's map the dataset! and see the first row:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176,
          "referenced_widgets": [
            "6eed902d72c3407d8ef4d9eaaf302847",
            "9550c86513f84215b9b8506a5dc7a127",
            "5f80aaecacfb4d509702ed6af95de534",
            "d4f03aa89fd648bf9992f391c9dd7ac6",
            "3c5c59311dc0479cbf5ebd03b5363360",
            "48ff5d0de0fe45c8aac710f6c0d883bb",
            "8476421707fa43528b9a9f683ae4b7dc",
            "b22730ff0db04854a9ab1283d0f99060",
            "7e6f52c1d06b4c18af608a5448f245a3",
            "2d5b486c177b402e8ae6bd87e40fa683",
            "1e16bb8225384620b0f9d1c1f7fd418e"
          ]
        },
        "id": "5tkTF5Hmlhl-",
        "outputId": "65d88d2c-7961-4e7a-eeac-435d29be7c8c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/31248 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6eed902d72c3407d8ef4d9eaaf302847"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'instruction': 'Aşağıdaki cümledeki kelimelere doğru NER etiketlerini ekleyin.',\n",
              " 'input': 'Albüm satış rakamlarıyla dikkat çekmiştir .',\n",
              " 'output': 'Albüm: O, satış: O, rakamlarıyla: O, dikkat: O, çekmiştir: O, .: O',\n",
              " 'prompt': [{'content': 'Aşağıdaki cümledeki kelimelere doğru NER etiketlerini ekleyin.',\n",
              "   'role': 'system'},\n",
              "  {'content': 'Albüm satış rakamlarıyla dikkat çekmiştir .', 'role': 'user'}],\n",
              " 'answer': 'Albüm: O, satış: O, rakamlarıyla: O, dikkat: O, çekmiştir: O, .: O'}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "dataset = dataset.map(lambda x: {\n",
        "    \"prompt\" : [\n",
        "        {\"role\": \"system\", \"content\": x[\"instruction\"]},\n",
        "        {\"role\": \"user\",   \"content\": x[\"input\"]},\n",
        "    ],\n",
        "    \"output\": x[\"output\"],\n",
        "})\n",
        "dataset[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ux6iqP7z5YOo"
      },
      "source": [
        "<a name=\"Train\"></a>\n",
        "### Train the model\n",
        "\n",
        "Now set up GRPO Trainer and all configurations!"
      ]
    },
    {
      "source": [
        "# Install the trl library\n",
        "!pip install trl"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5H86SfVj5AIT",
        "outputId": "d60bdb1c-4f16-4b86-a59f-2de00a2f3163"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting trl\n",
            "  Downloading trl-0.17.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: accelerate>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from trl) (1.6.0)\n",
            "Collecting datasets>=3.0.0 (from trl)\n",
            "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from trl) (13.9.4)\n",
            "Requirement already satisfied: transformers>=4.46.0 in /usr/local/lib/python3.11/dist-packages (from trl) (4.51.3)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (0.31.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (0.70.15)\n",
            "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.46.0->trl) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.46.0->trl) (0.21.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl) (2.19.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate>=0.34.0->trl) (4.13.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2025.4.26)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->accelerate>=0.34.0->trl)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->accelerate>=0.34.0->trl)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->accelerate>=0.34.0->trl)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate>=0.34.0->trl)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate>=0.34.0->trl)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate>=0.34.0->trl)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate>=0.34.0->trl)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate>=0.34.0->trl)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate>=0.34.0->trl)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate>=0.34.0->trl)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate>=0.34.0->trl) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate>=0.34.0->trl) (3.0.2)\n",
            "Downloading trl-0.17.0-py3-none-any.whl (348 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m348.0/348.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m94.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fsspec, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, datasets, trl\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 2.14.4\n",
            "    Uninstalling datasets-2.14.4:\n",
            "      Successfully uninstalled datasets-2.14.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.6.0 fsspec-2025.3.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 trl-0.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "ptqkXK2D4d6p",
        "outputId": "2afbd1c9-b0ea-4431-82b2-03a456a79b3b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'max_seq_length' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-a01b1b9f3945>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mnum_generations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Decrease if out of memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mmax_prompt_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_prompt_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mmax_completion_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_seq_length\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmax_prompt_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;31m# num_train_epochs = 1, # Set to 1 for a full training run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mmax_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'max_seq_length' is not defined"
          ]
        }
      ],
      "source": [
        "max_prompt_length = 256\n",
        "\n",
        "from trl import GRPOConfig, GRPOTrainer\n",
        "training_args = GRPOConfig(\n",
        "    learning_rate = 5e-6,\n",
        "    adam_beta1 = 0.9,\n",
        "    adam_beta2 = 0.99,\n",
        "    weight_decay = 0.1,\n",
        "    warmup_ratio = 0.1,\n",
        "    lr_scheduler_type = \"cosine\",\n",
        "    optim = \"adamw_torch_fused\",\n",
        "    logging_steps = 1,\n",
        "    per_device_train_batch_size = 1,\n",
        "    gradient_accumulation_steps = 1, # Increase to 4 for smoother training\n",
        "    num_generations = 4, # Decrease if out of memory\n",
        "    max_prompt_length = max_prompt_length,\n",
        "    max_completion_length = max_seq_length - max_prompt_length,\n",
        "    # num_train_epochs = 1, # Set to 1 for a full training run\n",
        "    max_steps = 50,\n",
        "    save_steps = 50,\n",
        "    max_grad_norm = 0.1,\n",
        "    report_to = \"none\", # Can use Weights & Biases\n",
        "    output_dir = \"outputs\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9Mv8UZO5hz-"
      },
      "source": [
        "And let's run the trainer! If you scroll up, you'll see a table of rewards. The goal is to see the `reward` column increase!\n",
        "\n",
        "You might have to wait 150 to 200 steps for any action. You'll probably get 0 reward for the first 100 steps. Please be patient!\n",
        "\n",
        "| Step | Training Loss | reward    | reward_std | completion_length | kl       |\n",
        "|------|---------------|-----------|------------|-------------------|----------|\n",
        "| 1    | 0.000000      | 0.125000  | 0.000000   | 200.000000        | 0.000000 |\n",
        "| 2    | 0.000000      | 0.072375  | 0.248112   | 200.000000        | 0.000000 |\n",
        "| 3    | 0.000000      | -0.079000 | 0.163776   | 182.500000        | 0.000005 |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vzOuSVCL_GA9",
        "outputId": "7fed464c-f2b6-4924-e98c-bc1c0a190887"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unsloth: Switching to float32 training since model cannot work with float16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 50\n",
            "O^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 1\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 1 x 1) = 4\n",
            " \"-____-\"     Trainable parameters = 6,522,880/1,006,408,832 (0.65% trained)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "******************** Question:\n",
            "A concert ticket costs $40. Mr. Benson bought 12 tickets and received a 5% discount for every ticket bought that exceeds 10. How much did Mr. Benson pay in all? \n",
            "Answer:\n",
            "476 \n",
            "Response:\n",
            "<start_working_out>\n",
            "Let $C$ be the cost of a ticket, which is $C = 40$.\n",
            "Let $N$ be the number of tickets Mr. Benson bought, which is $N = 12$.\n",
            "The total cost of the tickets without discount is $N \\times C = 12 \\times 40 = 480$.\n",
            "Mr. Benson received a 5% discount for every ticket bought that exceeds 10.\n",
            "The number of tickets that exceed 10 is $12 - 10 = 2$.\n",
            "The discount for each of these tickets is $5\\%$ of $10 = 0.05 \\times 10 = 0.5$.\n",
            "The discount amount for the 2 tickets is $2 \\times 0.5 = 1$.\n",
            "The discounted price for each of the 2 tickets is $10 - 0.5 = 9.5$.\n",
            "The total cost for the 2 tickets is $2 \\times 9.5 = 19$.\n",
            "The total cost of the tickets is the original cost minus the discount amount: $480 - 19 = 461$.\n",
            "However, this is incorrect because we need to consider the discounts for the tickets that exceed 10.\n",
            "Let $x$ be the number of tickets that exceed 10. We have $x = 12 - 10 = 2$.\n",
            "The discount is 5% for each ticket that exceeds 10.\n",
            "So the discounted price for each ticket is $40 \\times (1 - 0.05) = 40 \\times 0.95 = 38$.\n",
            "The total cost for the 2 tickets is $2 \\times 38 = 76$.\n",
            "The total cost of the 12 tickets is $12 \\times 40 = 480$.\n",
            "The total discount is $2 \\times 0.05 \\times 12 = 0.1 \\times 12 = 1.2$.\n",
            "The total cost after discount is $480 - 1.2 = 478.8$.\n",
            "However, we are given that Mr. Benson received a 5% discount for every ticket bought that exceeds 10.\n",
            "So, we need to calculate the number of tickets that exceed 10.\n",
            "Mr. Benson bought 12 tickets and received a 5% discount for every ticket bought that exceeds 10.\n",
            "The number of tickets that exceed 10 is $12 - 10 = 2$.\n",
            "The discount on each of these 2 tickets is $5\\%$ of $10$, which is $0.05 \\times 10 = 0.5$.\n",
            "The discount amount for each of the 2 tickets is $0.5 \\times 40 = 20$.\n",
            "The discounted price for each of the 2 tickets is $40 - 20 = 20$.\n",
            "The total cost for the 2 tickets is $2 \\times 20 = 40$.\n",
            "The total cost for the 12 tickets is $12 \\times 40 = 480$.\n",
            "The total discount is $2 \\times 0.5 = 1$.\n",
            "The total cost after discount is $480 - 1 = 479$.\n",
            "But this is not correct.\n",
            "\n",
            "Let $N = 12$. The cost per ticket is $40$.\n",
            "The discount is 5% for \n",
            "Extracted:\n",
            "None\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='14' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [14/50 13:12 < 39:36, 0.02 it/s, Epoch 0.00/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>reward</th>\n",
              "      <th>reward_std</th>\n",
              "      <th>completion_length</th>\n",
              "      <th>kl</th>\n",
              "      <th>rewards / match_format_exactly</th>\n",
              "      <th>rewards / match_format_approximately</th>\n",
              "      <th>rewards / check_answer</th>\n",
              "      <th>rewards / check_numbers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>758.250000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>0.577350</td>\n",
              "      <td>664.250000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>1.181454</td>\n",
              "      <td>411.000000</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.375000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>269.250000</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>155.250000</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>666.750000</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>409.500000</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>0.577350</td>\n",
              "      <td>496.250000</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.750000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>634.500000</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.750000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.250000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>558.750000</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.250000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>253.750000</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unsloth: Will smartly offload gradients to save VRAM!\n",
            "******************** Question:\n",
            "Jane is trying to decide whether to buy a house or a trailer. A house costs $480,000 and a trailer costs $120,000. Each loan will be paid in monthly installments over 20 years. How much more is the monthly payment on the house compared to the trailer? \n",
            "Answer:\n",
            "1500 \n",
            "Response:\n",
            "<start_working_out>\n",
            "We need to calculate the monthly payment on the house and the trailer.\n",
            "\n",
            "House cost: $480,000\n",
            "Loan amount: $480,000\n",
            "Interest rate: We need to assume an interest rate for this problem. Let's assume an annual interest rate of 6% (this is a common rate).\n",
            "Loan term: 20 years, so 20 * 12 = 240 months\n",
            "We will use the loan payment formula: M = P [ i(1 + i)^n ] / [ (1 + i)^n – 1]\n",
            "where M is the monthly payment, P is the loan amount, i is the monthly interest rate, and n is the number of months.\n",
            "\n",
            "Monthly interest rate (i) = Annual interest rate / 12 = 0.06 / 12 = 0.005\n",
            "Number of months (n) = 240\n",
            "\n",
            "M = 480000 [ 0.005(1 + 0.005)^240 ] / [ (1 + 0.005)^240 – 1]\n",
            "M = 480000 [ 0.005(1.005)^240 ] / [ (1.005)^240 – 1]\n",
            "M = 480000 [ 0.005 * 3.310853] / [ 3.310853 – 1]\n",
            "M = 480000 [ 0.016554265] / [2.310853]\n",
            "M = 480000 * 0.00703658\n",
            "M = $331.54\n",
            "\n",
            "Trailer cost: $120,000\n",
            "Loan amount: $120,000\n",
            "Interest rate: We still assume an annual interest rate of 6% (this is a common rate).\n",
            "Loan term: 20 years, so 20 * 12 = 240 months\n",
            "We will use the loan payment formula: M = P [ i(1 + i)^n ] / [ (1 + i)^n – 1]\n",
            "where M is the monthly payment, P is the loan amount, i is the monthly interest rate, and n is the number of months.\n",
            "\n",
            "Monthly interest rate (i) = Annual interest rate / 12 = 0.06 / 12 = 0.005\n",
            "Number of months (n) = 240\n",
            "\n",
            "M = 120000 [ 0.005(1 + 0.005)^240 ] / [ (1 + 0.005)^240 – 1]\n",
            "M = 120000 [ 0.005(1.005)^240 ] / [ (1.005)^240 – 1]\n",
            "M = 120000 [ 0.005 * 3.310853 ] / [ 3.310853 – 1]\n",
            "M = 120000 [ 0.016554265] / [2.310853]\n",
            "M = 1200 \n",
            "Extracted:\n",
            "None\n",
            "******************** Question:\n",
            "Janet pays $40/hour for 3 hours per week of clarinet lessons and $28/hour for 5 hours a week of piano lessons. How much more does she spend on piano lessons than clarinet lessons in a year? \n",
            "Answer:\n",
            "1040 \n",
            "Response:\n",
            "<start_working_out>\n",
            "Let $C$ be the amount Janet spends on clarinet lessons per week, and $P$ be the amount Janet spends on piano lessons per week.\n",
            "Janet pays $40/hour for 3 hours per week of clarinet lessons, so $C = 40 \\times 3 = 120$.\n",
            "Janet pays $28/hour for 5 hours a week of piano lessons, so $P = 28 \\times 5 = 140$.\n",
            "Janet's weekly spending on clarinet lessons is $120/week$, and her weekly spending on piano lessons is $140/week$.\n",
            "There are 52 weeks in a year.\n",
            "The amount she spends on clarinet lessons in a year is $120 \\times 52 = 6240$.\n",
            "The amount she spends on piano lessons in a year is $140 \\times 52 = 7280$.\n",
            "The difference between the amount she spends on piano lessons and clarinet lessons in a year is $7280 - 6240 = 1040$.\n",
            "\n",
            "<SOLUTION>\n",
            "The amount she spends on clarinet lessons in a year is $120 \\times 52 = 6240$.\n",
            "The amount she spends on piano lessons in a year is $140 \\times 52 = 7280$.\n",
            "The difference between the amount she spends on piano lessons and clarinet lessons in a year is $7280 - 6240 = 1040$.\n",
            "\n",
            "Final Answer: The final answer is $\\boxed{1040}$ \n",
            "Extracted:\n",
            "120\n",
            "******************** Question:\n",
            "Sabrina is collecting herbs to make a poultice for her grandmother. She needs twice as many basil leaves as sage leaves and 5 fewer sage leaves than verbena leaves. If she needs 12 basil leaves, how many leaves total does she need? \n",
            "Answer:\n",
            "29 \n",
            "Response:\n",
            "<start_working_out>\n",
            "Let $b$ be the number of basil leaves, $s$ be the number of sage leaves, and $v$ be the number of verbena leaves.\n",
            "We are given that Sabrina needs twice as many basil leaves as sage leaves, so $b = 2s$.\n",
            "We are also given that she needs 5 fewer sage leaves than verbena leaves, so $s = v - 5$.\n",
            "We are told that she needs 12 basil leaves, so $b = 12$.\n",
            "We can use the equation $b = 2s$ to solve for $s$:\n",
            "$12 = 2s$\n",
            "$s = \\frac{12}{2}$\n",
            "$s = 6$\n",
            "Now we can use the equation $s = v - 5$ to solve for $v$:\n",
            "$6 = v - 5$\n",
            "$v = 6 + 5$\n",
            "$v = 11$\n",
            "The total number of leaves needed is $b + s + v = 12 + 6 + 11$.\n",
            "$12 + 6 + 11 = 18 + 11 = 29$\n",
            "Therefore, the total number of leaves Sabrina needs is 29.\n",
            "\n",
            "<SOLUTION>29 \n",
            "Extracted:\n",
            "29\n",
            "******************** Question:\n",
            "Over the past five years, on July 4th, the high temperature for Washington, DC has been: 90 degrees in 2020, 90 degrees in 2019, 90 degrees in 2018, 79 degrees in 2017 and 71 degrees in 2016. What is the average temperature for July 4th in Washington, DC over the past 5 years? \n",
            "Answer:\n",
            "84 \n",
            "Response:\n",
            "<start_working_out>\n",
            "To find the average temperature, we need to sum the temperatures and divide by the number of years (5).\n",
            "\n",
            "The temperatures are: 90, 90, 90, 79, 71.\n",
            "\n",
            "Sum of temperatures = 90 + 90 + 90 + 79 + 71 = 410\n",
            "\n",
            "Number of years = 5\n",
            "\n",
            "Average temperature = 410 / 5 = 82\n",
            "\n",
            "<SOLUTION>82\n",
            " \n",
            "Extracted:\n",
            "82\n",
            "******************** Question:\n",
            "Rene can finish reading 30 pages in 60 minutes. Lulu can read 27 pages in 60 minutes and Cherry can read 25 pages in 60 minutes. If they have been reading for 240 minutes now, how many pages have they finished reading in total? \n",
            "Answer:\n",
            "328 \n",
            "Response:\n",
            "<start_working_out>\n",
            "Let R be the number of pages Rene finishes in 60 minutes.\n",
            "Let L be the number of pages Lulu finishes in 60 minutes.\n",
            "Let C be the number of pages Cherry finishes in 60 minutes.\n",
            "We are given that R = 30, L = 27, and C = 25.\n",
            "We are also given that they have been reading for 240 minutes.\n",
            "Rene finishes $\\frac{30}{60} = \\frac{1}{2}$ of a page per minute.\n",
            "Lulu finishes $\\frac{27}{60} = \\frac{9}{20}$ of a page per minute.\n",
            "Cherry finishes $\\frac{25}{60} = \\frac{5}{12}$ of a page per minute.\n",
            "The total number of pages they finish in 240 minutes is:\n",
            "$T = \\frac{1}{2}R + \\frac{9}{20}L + \\frac{5}{12}C$\n",
            "$T = \\frac{1}{2}(30) + \\frac{9}{20}(27) + \\frac{5}{12}(25)$\n",
            "$T = 15 + \\frac{243}{20} + \\frac{125}{12}$\n",
            "To add these terms, we need to find a common denominator for 20 and 12. The least common multiple of 20 and 12 is 120.\n",
            "$T = 15 + \\frac{243 \\cdot 6}{20 \\cdot 6} + \\frac{125 \\cdot 10}{12 \\cdot 10}$\n",
            "$T = 15 + \\frac{1458}{120} + \\frac{1250}{120}$\n",
            "$T = 15 + \\frac{1458 + 1250}{120}$\n",
            "$T = 15 + \\frac{2708}{120}$\n",
            "$T = 15 + \\frac{677}{30}$\n",
            "$T = 15 + 22.5666...$\n",
            "However, we are given that they have been reading for 240 minutes. We need to find the total number of pages finished.\n",
            "Let $x$ be the total number of pages they have finished.\n",
            "Rene finishes $R = 30$ pages in 60 minutes.\n",
            "Lulu finishes $L = 27$ pages in 60 minutes.\n",
            "Cherry finishes $C = 25$ pages in 60 minutes.\n",
            "The total pages finished in 60 minutes is $30 + 27 + 25 = 82$ pages.\n",
            "They have been reading for 240 minutes.\n",
            "The rate at which they finish pages is:\n",
            "Rene: $\\frac{30}{60} = \\frac{1}{2}$ pages per minute\n",
            "Lulu: $\\frac{27}{60} = \\frac{9}{20}$ pages per minute\n",
            "Cherry: $\\frac{25}{60} = \\frac{5}{12}$ pages per minute\n",
            "Total pages finished in 240 minutes:\n",
            "$T = \\frac{1}{2}R + \\frac{9}{20}L + \\frac{5}{12}C = \\frac{1}{2}( \n",
            "Extracted:\n",
            "None\n",
            "******************** Question:\n",
            "Martin rings the small bell 4 times more than 1/3 as often as the big bell. If he rings both of them a combined total of 52 times, how many times does he ring the big bell? \n",
            "Answer:\n",
            "36 \n",
            "Response:\n",
            "<start_working_out>\n",
            "Let $m$ be the number of times Martin rings the small bell, and $b$ be the number of times he rings the big bell.\n",
            "We are given that Martin rings the small bell 4 times more than 1/3 as often as the big bell. This can be written as\n",
            "$$m = \\frac{1}{3}b + 4$$\n",
            "We are also given that he rings both bells a combined total of 52 times. So,\n",
            "$$m + b = 52$$\n",
            "Now we have a system of two linear equations with two variables:\n",
            "$$m = \\frac{1}{3}b + 4$$\n",
            "$$m + b = 52$$\n",
            "Substitute the first equation into the second equation:\n",
            "$$\\left(\\frac{1}{3}b + 4\\right) + b = 52$$\n",
            "$$\\frac{1}{3}b + b = 52 - 4$$\n",
            "$$\\frac{4}{3}b = 48$$\n",
            "$$b = \\frac{3}{4} \\cdot 48$$\n",
            "$$b = 3 \\cdot 12$$\n",
            "$$b = 36$$\n",
            "Now, substitute $b = 36$ into the equation $m = \\frac{1}{3}b + 4$:\n",
            "$$m = \\frac{1}{3}(36) + 4$$\n",
            "$$m = 12 + 4$$\n",
            "$$m = 16$$\n",
            "So, Martin rings the small bell 16 times and the big bell 36 times. We want to find the number of times he rings the big bell, which is $b$.\n",
            "The number of times the big bell is $b = 36$.\n",
            "\n",
            "<SOLUTION>\n",
            "The number of times Martin rings the big bell is 36.\n",
            "Final Answer: The final answer is $\\boxed{36}$ \n",
            "Extracted:\n",
            "36.\n",
            "******************** Question:\n",
            "Bert fills out the daily crossword puzzle in the newspaper every day. He uses up a pencil to fill out the puzzles every two weeks. On average, it takes him 1050 words to use up a pencil. How many words are in each crossword puzzle on average? \n",
            "Answer:\n",
            "75 \n",
            "Response:\n",
            "<start_working_out>\n",
            "Let $w$ be the number of words in each crossword puzzle on average.\n",
            "Bert uses up a pencil to fill out the puzzles every two weeks.\n",
            "We are given that it takes him 1050 words to use up a pencil.\n",
            "Since he uses up a pencil every two weeks, the number of pencils he uses is $\\frac{2}{2} = 1$ pencil every two weeks.\n",
            "The total number of words used is $1 \\times w = w$ words.\n",
            "We are given that he uses up a pencil to fill out the puzzles every two weeks, and it takes him 1050 words to use up a pencil.\n",
            "Therefore, $w = 1050$.\n",
            "So, the number of words in each crossword puzzle on average is 1050.\n",
            "\n",
            "<SOLUTION>1050 \n",
            "Extracted:\n",
            "1050\n",
            "******************** Question:\n",
            "Matt can make a batch of a dozen cookies using 2 pounds of flour.  He uses 4 bags of flour each weighing 5 pounds.  If Jim eats 15 cookies how many cookies are left? \n",
            "Answer:\n",
            "105 \n",
            "Response:\n",
            "<start_working_out>\n",
            "Let $C$ be the number of cookies Matt can make.\n",
            "Matt can make a dozen cookies, which means he can make 12 cookies.\n",
            "He uses 2 pounds of flour to make a dozen cookies.\n",
            "He uses 4 bags of flour each weighing 5 pounds.\n",
            "So, the total weight of flour he uses is $4 \\times 5 = 20$ pounds.\n",
            "Since he makes a dozen cookies, the amount of flour he uses is 2 pounds.\n",
            "The total weight of flour he uses is 2 pounds.\n",
            "The number of cookies he can make is $\\frac{2}{5}$ dozen.\n",
            "A dozen is 12 cookies, so $\\frac{2}{5}$ dozen is $\\frac{2}{5} \\times 12 = \\frac{24}{5} = 4.8$ cookies.\n",
            "Since he can only make a whole number of cookies, we can assume he makes 4 cookies.\n",
            "He uses 2 pounds of flour.\n",
            "If he makes 4 cookies, he uses $\\frac{4}{12} \\times 2 = \\frac{1}{3} \\times 2 = \\frac{2}{3}$ pounds of flour.\n",
            "Jim eats 15 cookies.\n",
            "The number of cookies remaining is $15 - 4 = 11$ cookies.\n",
            "However, we don't need to calculate the value of the fraction of flour used.\n",
            "Let $x$ be the number of cookies Matt can make with 2 pounds of flour.\n",
            "$x = \\frac{2}{5} \\times 12 = \\frac{24}{5} = 4.8$ cookies.\n",
            "Since he can only make a whole number of cookies, we are given that Matt can make a dozen cookies, which is 12 cookies.\n",
            "He uses 2 pounds of flour for a dozen cookies.\n",
            "He uses 4 bags of flour each weighing 5 pounds. So he uses $4 \\times 5 = 20$ pounds of flour.\n",
            "Since he makes a dozen cookies, he uses $\\frac{2}{12} \\times 20 = \\frac{1}{6} \\times 20 = \\frac{20}{6} = \\frac{10}{3} = 3.33...$ pounds of flour.\n",
            "Jim eats 15 cookies.\n",
            "The number of cookies left is $12 - 15 = -3$, which is not possible.\n",
            "Let $n$ be the number of cookies Matt can make. He uses 2 pounds of flour.\n",
            "He uses 4 bags of flour, each weighing 5 pounds. So he uses $4 \\times 5 = 20$ pounds of flour.\n",
            "We have $n = \\frac{2}{5} \\times 12 = \\frac{24}{5} = 4.8$ cookies. Since he can only make whole cookies, he makes 4 cookies.\n",
            "Jim eats 15 cookies.\n",
            "The number of cookies remaining is $4 - 15 = -11$, which is not possible.\n",
            "Let $x$ be the number of cookies Matt makes. He uses 2 pounds of flour.\n",
            "He uses 4 bags of flour, each weighing 5 pounds. So he uses $4 \\times 5 = 20$ pounds of flour.\n",
            "We are given that he makes a dozen cookies, so $x = 12$.\n",
            "The amount of flour used is 2 pounds.\n",
            "The number of cookies Matt can make is $\\frac{ \n",
            "Extracted:\n",
            "None\n",
            "******************** Question:\n",
            "James decides to build a tin house by collecting 500 tins in a week. On the first day, he collects 50 tins. On the second day, he manages to collect 3 times that number. On the third day, he collects 50 tins fewer than the number he collected on the second day. If he collects an equal number of tins on the remaining days of the week, what's the number of tins he collected each day for the rest of the week? \n",
            "Answer:\n",
            "50 \n",
            "Response:\n",
            "<start_working_out>\n",
            "Let $x$ be the number of tins James collected on the third day.\n",
            "On the first day, he collected 50 tins.\n",
            "On the second day, he collected 3 times that number, so he collected $3 \\times 50 = 150$ tins.\n",
            "On the third day, he collected 50 tins fewer than the number he collected on the second day, so he collected $150 - 50 = 100$ tins.\n",
            "The total number of tins collected in the first three days is $50 + 150 + 100 = 300$ tins.\n",
            "He has 500 tins to collect in total, so the number of tins collected on the remaining days is $500 - 300 = 200$ tins.\n",
            "There are 7 days in a week. He collects an equal number of tins on the remaining 7 days.\n",
            "So, the number of tins collected on each of the remaining 7 days is $\\frac{200}{7} \\approx 28.57$. Since the number of tins must be an integer, we can't have a fraction. However, the problem states that he collects an equal number of tins on the remaining days of the week.\n",
            "\n",
            "Let $n$ be the number of tins collected on each of the remaining 7 days. Then $7n = 200$.\n",
            "$n = \\frac{200}{7} \\approx 28.57$. Since the number of tins collected must be an integer, we need to re-evaluate.\n",
            "\n",
            "Let $x$ be the number of tins collected on the first day.\n",
            "Let $y$ be the number of tins collected on the second day.\n",
            "Let $z$ be the number of tins collected on the third day.\n",
            "Let $w$ be the number of tins collected on the fourth day.\n",
            "Let $v$ be the number of tins collected on the fifth day.\n",
            "Let $u$ be the number of tins collected on the sixth day.\n",
            "Let $t$ be the number of tins collected on the seventh day.\n",
            "\n",
            "We are given:\n",
            "$x = 50$\n",
            "$y = 3x = 3(50) = 150$\n",
            "$z = y - 50 = 150 - 50 = 100$\n",
            "$w = x - 50 = 50 - 50 = 0$\n",
            "$v = w + z = 0 + 100 = 100$\n",
            "$u = v + t = 100 + t$\n",
            "$t = 500 - (x + y + z + w + v + u) = 500 - (50 + 150 + 100 + 0 + 100 + (100+t)) = 500 - (50 + 150 + 100 + 0 + 100 + 100 + t) = 500 - (400 + 300 + t) = 500 - (700 + t) = -200 - t$\n",
            "Since $t$ must be non-negative, we have $-200 - t \\geq 0$, so $t \\leq -200$. This is not possible.\n",
            "\n",
            "Let's re-interpret the problem.\n",
            "James collects 50 tins on \n",
            "Extracted:\n",
            "None\n",
            "******************** Question:\n",
            "A jar of jellybeans has 14 blue jellybeans, 26 purple jellybeans and 40 orange jellybeans. If there are 200 jellybeans in the jar, how many are there of the red color? \n",
            "Answer:\n",
            "120 \n",
            "Response:\n",
            "<start_working_out>\n",
            "Let $B$ be the number of blue jellybeans, $P$ be the number of purple jellybeans, and $O$ be the number of orange jellybeans.\n",
            "We are given that $B = 14$, $P = 26$, and $O = 40$.\n",
            "The total number of jellybeans is $B + P + O = 14 + 26 + 40 = 80$.\n",
            "We are told that there are 200 jellybeans in the jar.\n",
            "Let $R$ be the number of red jellybeans.\n",
            "The total number of jellybeans is the sum of the number of blue, purple, orange, and red jellybeans.\n",
            "So, $B + P + O + R = 200$.\n",
            "Substituting the given values, we have $14 + 26 + 40 + R = 200$.\n",
            "$80 + R = 200$.\n",
            "$R = 200 - 80$.\n",
            "$R = 120$.\n",
            "Therefore, there are 120 red jellybeans in the jar.\n",
            "\n",
            "<SOLUTION>120 \n",
            "Extracted:\n",
            "120\n",
            "******************** Question:\n",
            "Five adults and two children go to see a movie and buy $12 worth of concessions. The total cost of their trip is $76. If each child's ticket is $7, how much, in dollars, are the adult tickets? \n",
            "Answer:\n",
            "10 \n",
            "Response:\n",
            "<start_working_out>\n",
            "Let $a$ be the number of adult tickets and $c$ be the number of children's tickets.\n",
            "We are given that there are five adults and two children, so $a+c = 5+2 = 7$.\n",
            "We are also given that the total cost of the trip is $12 worth of concessions, and the total cost is $76. So, $7a + 7c = 76$.\n",
            "We have a system of two linear equations with two variables:\n",
            "\\begin{align*} \\label{eq:1} a+c &= 7 \\\\ 7a+7c &= 76\\end{align*}\n",
            "From the first equation, we can write $c = 7-a$. Substitute this into the second equation:\n",
            "$$7a + 7(7-a) = 76$$\n",
            "$$7a + 49 - 7a = 76$$\n",
            "$$49 = 76$$\n",
            "This equation is inconsistent, so we must have made a mistake.\n",
            "Let's try another approach. Let $x$ be the price of an adult ticket and $y$ be the price of a child's ticket.\n",
            "We are given that there are five adults and two children, so $a$ is the number of adult tickets and $c$ is the number of children's tickets.\n",
            "We are given that there are 5 adults and 2 children, so $a+c = 5+2 = 7$.\n",
            "We are given that the total cost is $12 worth of concessions.\n",
            "The cost of the adult tickets is $ax$ and the cost of the children's tickets is $cy$.\n",
            "The total cost is $ax + cy = 12$.\n",
            "We are given that each child's ticket is $7, so $y = 7$.\n",
            "Thus, $ax + 7c = 12$.\n",
            "Since $a+c = 7$, we can write $c = 7-a$. Substitute this into the equation:\n",
            "$$ax + 7(7-a) = 12$$\n",
            "$$ax + 49 - 7a = 12$$\n",
            "$$ax - 7a = 12 - 49$$\n",
            "$$a(x-7) = -37$$\n",
            "$$a = \\frac{-37}{x-7}$$\n",
            "Since $a$ and $c$ must be integers, $x-7$ must be a factor of 37. Since 37 is a prime number, $x-7$ can be $1$ or $37$.\n",
            "If $x-7 = 1$, then $x = 8$. Then $a = \\frac{-37}{1} = -37$, which is not possible.\n",
            "If $x-7 = 37$, then $x = 44$. Then $a = \\frac{-37}{37} = -1$, which is not possible.\n",
            "Let's try a different approach.\n",
            "The total cost of the trip is $12. The number of adults is $a$ and the number of children is $c$.\n",
            "$$ax + 7c = 12$$\n",
            "We are given that there are 5 adults and 2 children, so $a+c = 5+2 = 7$.\n",
            "Substituting $c = 7-a$ into the equation, we get\n",
            "$$ax + 7(7-a) = 12$$\n",
            "$$ax + 49 \n",
            "Extracted:\n",
            "None\n",
            "******************** Question:\n",
            "Janelle had 26 green marbles. Then she bought 6 bags of blue marbles. There were 10 marbles in each bag.  She created a gift of 6 green marbles and 8 blue marbles and gave it to a friend. How many marbles does Janelle have now? \n",
            "Answer:\n",
            "72 \n",
            "Response:\n",
            "<start_working_out>\n",
            "Janelle starts with 26 green marbles.\n",
            "She buys 6 bags of blue marbles, with 10 marbles in each bag. So she buys 6 * 10 = 60 marbles of blue.\n",
            "Now she has 26 + 60 = 86 marbles.\n",
            "She creates a gift of 6 green marbles and 8 blue marbles.\n",
            "So she has 6 green marbles + 8 blue marbles = 14 marbles.\n",
            "After creating the gift, she has 86 - 14 = 72 marbles.\n",
            "<end_working_out>\n",
            "Janelle has 72 marbles now.\n",
            " \n",
            "Extracted:\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "trainer = GRPOTrainer(\n",
        "    model = model,\n",
        "    processing_class = tokenizer,\n",
        "    reward_funcs = [\n",
        "        match_format_exactly,\n",
        "        match_format_approximately,\n",
        "        check_answer,\n",
        "        check_numbers,\n",
        "    ],\n",
        "    args = training_args,\n",
        "    train_dataset = dataset,\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlaUdxC_VHpz"
      },
      "source": [
        "<a name=\"Inference\"></a>\n",
        "### Inference\n",
        "Now let's try the model we just trained!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtcz_lpbVC92",
        "outputId": "bc1e6dbc-4e4e-4382-f7aa-1f56e716f044"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<start_working_out>\n",
            "The square root of 101 is approximately 10.0498756.\n",
            "<SOLUTION>\n",
            "10.0498756<end_of_turn>\n"
          ]
        }
      ],
      "source": [
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": system_prompt},\n",
        "    {\"role\": \"user\",   \"content\": \"What is the sqrt of 101?\"},\n",
        "]\n",
        "\n",
        "text = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    add_generation_prompt = True, # Must add for generation\n",
        "    tokenize = False,\n",
        ")\n",
        "from transformers import TextStreamer\n",
        "_ = model.generate(\n",
        "    **tokenizer(text, return_tensors = \"pt\").to(\"cuda\"),\n",
        "    max_new_tokens = 64, # Increase for longer outputs!\n",
        "    # Recommended Gemma-3 settings!\n",
        "    temperature = 1.0, top_p = 0.95, top_k = 64,\n",
        "    streamer = TextStreamer(tokenizer, skip_prompt = True),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NUEmHFSYNTp"
      },
      "source": [
        "<a name=\"Save\"></a>\n",
        "### Saving, loading finetuned models\n",
        "To save the final model as LoRA adapters, either use Huggingface's `push_to_hub` for an online save or `save_pretrained` for a local save.\n",
        "\n",
        "**[NOTE]** This ONLY saves the LoRA adapters, and not the full model. To save to 16bit or GGUF, scroll down!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjXGTkp7YNtB",
        "outputId": "7dbe3643-d756-4c32-acaf-2d5fe76f52ef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('gemma-3/tokenizer_config.json',\n",
              " 'gemma-3/special_tokens_map.json',\n",
              " 'gemma-3/tokenizer.model',\n",
              " 'gemma-3/added_tokens.json',\n",
              " 'gemma-3/tokenizer.json')"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.save_pretrained(\"gemma-3\")  # Local saving\n",
        "tokenizer.save_pretrained(\"gemma-3\")\n",
        "# model.push_to_hub(\"HF_ACCOUNT/gemma-3\", token = \"...\") # Online saving\n",
        "# tokenizer.push_to_hub(\"HF_ACCOUNT/gemma-3\", token = \"...\") # Online saving"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52WMb3k_YPt8"
      },
      "source": [
        "### Saving to float16 for VLLM\n",
        "\n",
        "We also support saving to `float16` directly for deployment! We save it in the folder `gemma-3-finetune`. Set `if False` to `if True` to let it run!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QyEjW-WuYQIm"
      },
      "outputs": [],
      "source": [
        "if False: # Change to True to save finetune!\n",
        "    model.save_pretrained_merged(\"gemma-3-finetune\", tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRrqfyaRaXRL"
      },
      "source": [
        "If you want to upload / push to your Hugging Face account, set `if False` to `if True` and add your Hugging Face token and upload location!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-B07m_HC5i7"
      },
      "outputs": [],
      "source": [
        "if False: # Change to True to upload finetune\n",
        "    model.push_to_hub_merged(\n",
        "        \"HF_ACCOUNT/gemma-3-finetune\", tokenizer,\n",
        "        token = \"hf_...\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JMDDS0bC7jT"
      },
      "source": [
        "### GGUF / llama.cpp Conversion\n",
        "To save to `GGUF` / `llama.cpp`, we support it natively now for all models! For now, you can convert easily to `Q8_0, F16 or BF16` precision. `Q4_K_M` for 4bit will come later!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aX3xMj8hC6e0"
      },
      "outputs": [],
      "source": [
        "if False: # Change to True to save to GGUF\n",
        "    model.save_pretrained_gguf(\n",
        "        \"gemma-3-finetune\",\n",
        "        quantization_type = \"Q8_0\", # For now only Q8_0, BF16, F16 supported\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CfqZW5rC9zv"
      },
      "source": [
        "Likewise, if you want to instead push to GGUF to your Hugging Face account, set `if False` to `if True` and add your Hugging Face token and upload location!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SG6-dP0JC-G2"
      },
      "outputs": [],
      "source": [
        "if False: # Change to True to upload GGUF\n",
        "    model.push_to_hub_gguf(\n",
        "        \"gemma-3-finetune\",\n",
        "        quantization_type = \"Q8_0\", # Only Q8_0, BF16, F16 supported\n",
        "        repo_id = \"HF_ACCOUNT/gemma-finetune-gguf\",\n",
        "        token = \"hf_...\",\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-F2GVrPrDArH"
      },
      "source": [
        "Now, use the `gemma-3-finetune.gguf` file or `gemma-3-finetune-Q4_K_M.gguf` file in llama.cpp or a UI based system like Jan or Open WebUI. You can install Jan [here](https://github.com/janhq/jan) and Open WebUI [here](https://github.com/open-webui/open-webui)\n",
        "\n",
        "And we're done! If you have any questions on Unsloth, we have a [Discord](https://discord.gg/unsloth) channel! If you find any bugs or want to keep updated with the latest LLM stuff, or need help, join projects etc, feel free to join our Discord!\n",
        "\n",
        "Some other links:\n",
        "1. Train your own reasoning model - Llama GRPO notebook [Free Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.1_(8B)-GRPO.ipynb)\n",
        "2. Saving finetunes to Ollama. [Free notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3_(8B)-Ollama.ipynb)\n",
        "3. Llama 3.2 Vision finetuning - Radiography use case. [Free Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_(11B)-Vision.ipynb)\n",
        "6. See notebooks for DPO, ORPO, Continued pretraining, conversational finetuning and more on our [documentation](https://docs.unsloth.ai/get-started/unsloth-notebooks)!\n",
        "\n",
        "<div class=\"align-center\">\n",
        "  <a href=\"https://unsloth.ai\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "  <a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord.png\" width=\"145\"></a>\n",
        "  <a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a>\n",
        "\n",
        "  Join Discord if you need help + ⭐️ <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ⭐️\n",
        "</div>\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6eed902d72c3407d8ef4d9eaaf302847": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9550c86513f84215b9b8506a5dc7a127",
              "IPY_MODEL_5f80aaecacfb4d509702ed6af95de534",
              "IPY_MODEL_d4f03aa89fd648bf9992f391c9dd7ac6"
            ],
            "layout": "IPY_MODEL_3c5c59311dc0479cbf5ebd03b5363360"
          }
        },
        "9550c86513f84215b9b8506a5dc7a127": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48ff5d0de0fe45c8aac710f6c0d883bb",
            "placeholder": "​",
            "style": "IPY_MODEL_8476421707fa43528b9a9f683ae4b7dc",
            "value": "Map: 100%"
          }
        },
        "5f80aaecacfb4d509702ed6af95de534": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b22730ff0db04854a9ab1283d0f99060",
            "max": 31248,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7e6f52c1d06b4c18af608a5448f245a3",
            "value": 31248
          }
        },
        "d4f03aa89fd648bf9992f391c9dd7ac6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d5b486c177b402e8ae6bd87e40fa683",
            "placeholder": "​",
            "style": "IPY_MODEL_1e16bb8225384620b0f9d1c1f7fd418e",
            "value": " 31248/31248 [00:03&lt;00:00, 5669.92 examples/s]"
          }
        },
        "3c5c59311dc0479cbf5ebd03b5363360": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48ff5d0de0fe45c8aac710f6c0d883bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8476421707fa43528b9a9f683ae4b7dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b22730ff0db04854a9ab1283d0f99060": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e6f52c1d06b4c18af608a5448f245a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2d5b486c177b402e8ae6bd87e40fa683": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e16bb8225384620b0f9d1c1f7fd418e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}